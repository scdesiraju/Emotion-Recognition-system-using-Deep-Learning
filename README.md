# Emotion-Recognition-system-using-Deep-Learning

## Abstract
Human emotions play a crucial role in interpersonal communication. Recognizing facial emotions has garnered significant interest in various fields due to its potential applications. This project focuses on identifying emotions from facial images using Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN). The system aims to classify emotions into categories such as happiness, sadness, anger, disgust, and surprise. The developed model holds promise for applications in feedback systems, face unlocking, security surveillance, and healthcare.

## Introduction
Facial expression recognition is a pivotal aspect of human interaction, allowing individuals to convey their emotions effectively. This project addresses the challenge of automating emotion recognition from facial images. By leveraging CNNs and RNNs, the system detects and classifies emotions with high accuracy. The objective is to facilitate seamless communication, especially for individuals with speech impairments or restricted mobility.

## Problem Definition
The project aims to develop a robust system capable of accurately recognizing facial emotions in real-time. This includes detecting emotions such as anger, disgust, fear, happiness, sadness, surprise, and neutrality. The significance lies in enhancing communication, building trust, and enabling access to emotional expression for all individuals, including those with disabilities.

## Methodologies
The project utilizes CNNs for feature extraction from facial images and RNNs for sequential data analysis. CNNs automatically extract relevant features from images, while RNNs capture temporal dependencies in emotion recognition. The combined approach enables the system to accurately classify emotions and facilitate real-time processing.

## Objectives
Develop a system for real-time facial emotion recognition.
Classify emotions into predefined categories.
Enable communication through facial expressions.
Enhance accessibility for individuals with disabilities.
Achieve high accuracy in emotion classification.

## Scope of the Project
The project encompasses the development of an application capable of real-time facial emotion recognition. Key functionalities include image capturing, face detection, emotion classification, and displaying emotion probabilities. The system aims to provide accurate and intuitive emotion recognition for various applications.

## Design of Proposed System
The system architecture consists of modules for data collection, augmentation, training, testing, and visualization. CNNs and RNNs form the core components for feature extraction and emotion classification.

### Libraries Used
Keras: for building and training neural network models.

scikit-learn: for machine learning algorithms and evaluation.

OpenCV (cv2): for image processing and computer vision tasks.

NumPy: for numerical computation and array manipulation.

TensorFlow: for creating and deploying machine learning models.

## Results
The system achieves an accuracy of 74.20% in facial emotion recognition. It accurately identifies emotions such as anger, disgust, fear, happiness, sadness, surprise, and neutrality. The application is compatible with Windows and Linux platforms and provides real-time emotion classification capabilities.

## Conclusion and Future Work
Facial emotion recognition holds immense potential for improving communication and understanding human behavior. The developed system demonstrates promising results in emotion classification. Future work involves expanding the dataset, optimizing model performance, and exploring real-time deployment options.

## Limitations
Computational resources limit the model's training and testing capabilities.
Increased epochs require substantial processing time and memory resources.

## Future Work
Expand the dataset to improve model generalization.
Optimize model architecture for real-time performance.
Explore deployment options for practical applications.
